import os
import time
import uuid
from typing import Dict, List, Optional
import google.generativeai as genai
from openai import OpenAI

class AIAgentService:
    def __init__(self):
        self.gemini_api_key = os.getenv("GEMINI_API_KEY")
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        
        # Configuration Gemini
        if self.gemini_api_key:
            genai.configure(api_key=self.gemini_api_key)
            self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # Configuration OpenAI
        if self.openai_api_key:
            self.openai_client = OpenAI(api_key=self.openai_api_key)
        
        # Contexte systÃ¨me par dÃ©faut
        self.system_context = """Tu es un assistant IA intelligent et serviable intÃ©grÃ© dans WeBox, 
une plateforme de crÃ©ation de contenu IA. Tu aides les utilisateurs avec :
- La crÃ©ation de podcasts
- La gÃ©nÃ©ration d'avatars
- Des conseils sur l'utilisation de l'IA
- Des rÃ©ponses rapides et prÃ©cises

Tu es disponible 24/7 et tu rÃ©ponds toujours de maniÃ¨re professionnelle, claire et utile.
Sois concis mais complet dans tes rÃ©ponses."""
    
    def generate_session_id(self) -> str:
        """GÃ©nÃ¨re un ID de session unique"""
        return f"session_{uuid.uuid4().hex[:16]}"
    
    async def chat(self, message: str, conversation_history: List[Dict], model: str = "gemini-2.0-flash") -> Dict:
        """
        Envoie un message Ã  l'IA et retourne la rÃ©ponse
        
        Args:
            message: Message de l'utilisateur
            conversation_history: Historique de la conversation
            model: ModÃ¨le Ã  utiliser
        
        Returns:
            Dict avec la rÃ©ponse et les mÃ©tadonnÃ©es
        """
        start_time = time.time()
        
        try:
            if model.startswith("gemini"):
                return await self._chat_gemini(message, conversation_history)
            elif model.startswith("gpt"):
                return await self._chat_openai(message, conversation_history, model)
            else:
                return {
                    "success": False,
                    "error": f"ModÃ¨le non supportÃ© : {model}"
                }
        except Exception as e:
            return {
                "success": False,
                "error": f"Erreur lors de la gÃ©nÃ©ration : {str(e)}"
            }
    
    async def _chat_gemini(self, message: str, history: List[Dict]) -> Dict:
        """Chat avec Gemini"""
        try:
            # Construire l'historique pour Gemini
            gemini_history = []
            for msg in history[-10:]:  # Garder les 10 derniers messages
                role = "user" if msg["role"] == "user" else "model"
                gemini_history.append({
                    "role": role,
                    "parts": [msg["content"]]
                })
            
            # CrÃ©er le chat
            chat = self.gemini_model.start_chat(history=gemini_history)
            
            # Envoyer le message
            start_time = time.time()
            response = chat.send_message(message)
            response_time = int((time.time() - start_time) * 1000)
            
            return {
                "success": True,
                "content": response.text,
                "model": "gemini-2.0-flash",
                "response_time": response_time,
                "tokens": len(response.text.split())  # Approximation
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Erreur Gemini : {str(e)}"
            }
    
    async def _chat_openai(self, message: str, history: List[Dict], model: str) -> Dict:
        """Chat avec OpenAI"""
        try:
            # Construire les messages pour OpenAI
            messages = [{"role": "system", "content": self.system_context}]
            
            # Ajouter l'historique
            for msg in history[-10:]:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            # Ajouter le nouveau message
            messages.append({"role": "user", "content": message})
            
            # Envoyer Ã  OpenAI
            start_time = time.time()
            response = self.openai_client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7
            )
            response_time = int((time.time() - start_time) * 1000)
            
            return {
                "success": True,
                "content": response.choices[0].message.content,
                "model": model,
                "response_time": response_time,
                "tokens": response.usage.total_tokens
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Erreur OpenAI : {str(e)}"
            }
    
    def generate_title(self, first_message: str) -> str:
        """GÃ©nÃ¨re un titre pour la conversation basÃ© sur le premier message"""
        # Prendre les 50 premiers caractÃ¨res
        title = first_message[:50]
        if len(first_message) > 50:
            title += "..."
        return title
    
    def get_available_models(self) -> List[Dict]:
        """Retourne la liste des modÃ¨les disponibles"""
        models = []
        
        if self.gemini_api_key:
            models.append({
                "id": "gemini-2.0-flash",
                "name": "Gemini 2.0 Flash",
                "provider": "Google",
                "speed": "ultra-fast",
                "cost": "free",
                "icon": "âš¡"
            })
        
        if self.openai_api_key:
            models.extend([
                {
                    "id": "gpt-4o",
                    "name": "GPT-4o",
                    "provider": "OpenAI",
                    "speed": "fast",
                    "cost": "low",
                    "icon": "ğŸ¤–"
                },
                {
                    "id": "gpt-4o-mini",
                    "name": "GPT-4o Mini",
                    "provider": "OpenAI",
                    "speed": "very-fast",
                    "cost": "very-low",
                    "icon": "âš¡"
                }
            ])
        
        return models
    
    def get_quick_actions(self) -> List[Dict]:
        """Retourne les actions rapides suggÃ©rÃ©es"""
        return [
            {
                "id": "create_podcast",
                "icon": "ğŸ™ï¸",
                "title": "CrÃ©er un podcast",
                "prompt": "Je veux crÃ©er un podcast sur..."
            },
            {
                "id": "create_avatar",
                "icon": "ğŸ‘¤",
                "title": "CrÃ©er un avatar",
                "prompt": "Je veux crÃ©er un avatar..."
            },
            {
                "id": "help",
                "icon": "â“",
                "title": "Aide",
                "prompt": "Comment utiliser WeBox ?"
            },
            {
                "id": "ideas",
                "icon": "ğŸ’¡",
                "title": "IdÃ©es de contenu",
                "prompt": "Donne-moi des idÃ©es de contenu Ã  crÃ©er"
            }
        ]
